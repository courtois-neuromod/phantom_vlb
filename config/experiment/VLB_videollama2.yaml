# @package _global_

datamodule:
  _target_:
    src.datamodule.videollama2_vlb_datamodule.VLBDataModule
  config:
    _target_:
      src.datamodule.videollama2_vlb_datamodule.VLBDataModuleConfig
    features_path: ./results/videollama2/lazyloading/friends/friends_*_features.h5
    timeseries_path:
      "../cneuromod_extract_tseries/outputs/friends/${subject}/func/${subject}_task-friends_space-\
      MNI152NLin2009cAsym_atlas-Schaefer18_desc-1000Parcels7Networks_timeseries.h5"
    lazyload_path: $SLURM_TMPDIR/friends_${subject}_llFile.h5
    delay: 3
    window: 3
    seasons: [s01, s02, s04, s05, s06]
    subject: ${subject}
    random_state: ${random_state}
    batch_size: 1
    num_workers: 0
    shuffle_val_data: True

litmodule:
  _target_:
    src.litmodule.videollama2_vlb_litmodule.VLBLitModule
  config:
    _target_:
      src.litmodule.videollama2_vlb_litmodule.VLBLitModuleConfig
    model_type: videollama2
    model_path: mistralai/Mistral-7B-Instruct-v0.2
    pretrain_mm_mlp_adapter: DAMO-NLP-SG/VideoLLaMA2-7B-Base/mm_projector.bin
    freeze_backbone: False

# https://pytorch.org/docs/stable/generated/torch.optim.AdamW
optimizer:
  _target_: torch.optim.AdamW
  _partial_: True  # https://hydra.cc/docs/advanced/instantiate_objects/overview/
  betas: [0.9, 0.999]
  eps: 1e-08
  lr: 1e-3
  weight_decay: 1e-2

hydra:
  setup:
    - echo $SLURM_TMPDIR

output_dir: ./results/videollama2/brain_finetune/friends/lightning_ckpt

name: vllama2_vlb_friends
