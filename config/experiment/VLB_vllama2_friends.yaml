# @package _global_

datamodule:
  _target_:
    src.datamodule.VLBDataModule
  config:
    _target_:
      src.datamodule.VLBDataModuleConfig
    features_path: $SLURM_TMPDIR/friends_*_features.h5
    timeseries_path:
      "$SLURM_TMPDIR/${subject}_task-friends_space-\
      MNI152NLin2009cAsym_atlas-Schaefer18_desc-1000Parcels7Networks_timeseries.h5"
    lazyload_path: $SLURM_TMPDIR/friends_${subject}_*_llFile.h5
    delay: 3
    window: 3
    seasons: [s01, s02, s04, s05, s06]
    subject: ${subject}
    random_state: ${random_state}
    batch_size: 1
    num_workers: 1
    shuffle_val_data: True

litmodule:
  _target_:
    src.litmodule.VLBLitModule
  config:
    _target_:
      src.litmodule.VLBLitModuleConfig
    model_path: DAMO-NLP-SG/VideoLLaMA2-7B
    freeze_backbone: False
    dropout_rate: 0.2
    num_target: 1000
    l2_lambda: 0.001
    lr: 1e-3
    betas: [0.9, 0.999]
    eps: 1e-08
    weight_decay: 1e-2
    lr_scheduler_name: CosineAnnealingLR
    last_epoch: -1
    t_max: 50000

trainer:
  _target_: lightning.pytorch.Trainer
  precision: "16-mixed"
  accelerator: "gpu"
  gradient_clip_val: 1
  devices: 4
  num_nodes: 1
  max_epochs: 150
  max_steps: Null
  val_check_interval: 0.5
  log_every_n_steps: 15

exp_logger:
  _target_: lightning.pytorch.loggers.CometLogger
  api_key: ${my_api_key}
  workspace: ${my_workspace}
  project_name: phantom_mm
  name: vllama2_vlb_friends_logs

output_dir: ./results/videollama2/brain_finetune/friends/lightning_ckpt

name: vllama2_vlb_friends
